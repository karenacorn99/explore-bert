{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "explore-vocab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a10dcb61b6a419bb08fb365d695cf82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e64363040e7f4e498cf4b264d0ab4ae8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b871876a776460a9fbae2724329d68e",
              "IPY_MODEL_3f62010d71fd445c9a4a20ef08f47b3a"
            ]
          }
        },
        "e64363040e7f4e498cf4b264d0ab4ae8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b871876a776460a9fbae2724329d68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_06485a925a44468aa74ff019c4ed6099",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c1958cd3dff49f18e4fc21e6cd8afa4"
          }
        },
        "3f62010d71fd445c9a4a20ef08f47b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e3b334b697504143be519326bd214bd3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 896kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a041651df1a490ebe3a48eac5aadbf2"
          }
        },
        "06485a925a44468aa74ff019c4ed6099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c1958cd3dff49f18e4fc21e6cd8afa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3b334b697504143be519326bd214bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a041651df1a490ebe3a48eac5aadbf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYKAvMhCV5uM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b8be93a4-bf37-4f9e-85a7-e34d621a26a4"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaExH-QUXVzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "993884a8-73ba-4420-a7a5-3b8412cb31d6"
      },
      "source": [
        "%cd drive/My\\ Drive/Explore-Bert"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Explore-Bert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHadx0ItV1Tn",
        "colab_type": "text"
      },
      "source": [
        "### Explore Bert Vocabulary ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MoZSrpXV1Ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_file = \"./uncased_L-12_H-768_A-12/vocab.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRNPosSFV1T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read all bert vocab as a list\n",
        "bert_vocab = open(vocab_file, 'r').read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pup78N3V1T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "[PAD]\n",
        "[unused0] - [unused98]\n",
        "[UNK]: (index 101)unknown token\n",
        "[CLS]: (index 102)added in front of every input\n",
        "[SEP]: (index 103)separator token\n",
        "[MASK]: (index104)reduce mismatch between pre-training and fine-tuning, does not appear in fine-tuning\n",
        "[unused99] - [used993]\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksWCj5STV1T8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "puntuations\n",
        "numbers\n",
        "punctuations\n",
        "English alphabets\n",
        "puntuations\n",
        "Greek alphabets\n",
        "other languages\n",
        "Hiragana\n",
        "Katakana\n",
        "Chinese(radicals?): both simplified and traditional\n",
        "' (' and '(' are two separate tokens\n",
        "') ' and ')' are two separate tokens\n",
        "single English words:\n",
        "##s\n",
        "numbers\n",
        "##chinese character\n",
        "'''\n",
        "# more details in Inspect BERT Vocabulary.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCjOr5pRV1T_",
        "colab_type": "code",
        "outputId": "27c7df35-aac8-4902-99cb-86d31e5062ab",
        "colab": {}
      },
      "source": [
        "# longest word\n",
        "sorted_vocab = sorted(bert_vocab, key = len, reverse = True)\n",
        "print(\"Longest word is '{}', it has length {}.\".format(sorted_vocab[0], len(sorted_vocab[0])))\n",
        "print(\"Shortet word is '{}', it has length {}.\".format(sorted_vocab[-1], len(sorted_vocab[-1])))\n",
        "# empty string is part of the vocab\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longest word is 'telecommunications', it has length 18.\n",
            "Shortet word is '', it has length 0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biepfDvFV1UD",
        "colab_type": "code",
        "outputId": "40e02636-1af6-433d-997a-b8ecf59cd7e3",
        "colab": {}
      },
      "source": [
        "# get all numbers\n",
        "numbers = [word for word in bert_vocab if word.isdigit()]\n",
        "print(len(numbers))\n",
        "#print(numbers)\n",
        "# subscripts and superscripts are also in the vocab #\n",
        "# 000 #\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYbYtH3LV1UG",
        "colab_type": "code",
        "outputId": "369e78e3-187a-4ef6-c3f4-e926a1c69845",
        "colab": {}
      },
      "source": [
        "# get all English words\n",
        "# first appearance of single English word\n",
        "print(bert_vocab[1996])\n",
        "# last appearance of single English word\n",
        "print(bert_vocab[29611])\n",
        "eng_words = bert_vocab[1996:29612]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the\n",
            "necessitated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLlRqkSjV1UJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# explore Bert vocabulary with respect to my dataset\n",
        "story_file = \"../final_stories.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZHpGA60V1UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqm-kFgCV1UN",
        "colab_type": "code",
        "outputId": "3044fa98-b8a2-41a3-c1d4-c7ae9f67f6b7",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(story_file)\n",
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seed</th>\n",
              "      <th>buildup</th>\n",
              "      <th>climax</th>\n",
              "      <th>resolution</th>\n",
              "      <th>outlook</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1250</td>\n",
              "      <td>1250</td>\n",
              "      <td>1250</td>\n",
              "      <td>1250</td>\n",
              "      <td>1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>250</td>\n",
              "      <td>1250</td>\n",
              "      <td>1238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Naomi's friend Noah invited her to his house.</td>\n",
              "      <td>Mitch thought the book looked cheap and told J...</td>\n",
              "      <td>Kate was very uncomfortable and stood at one c...</td>\n",
              "      <td>Neil was glad to have joined the conversation,...</td>\n",
              "      <td>Alice and Sam's friendship will continue to gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>125</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 seed  \\\n",
              "count                                            1250   \n",
              "unique                                             10   \n",
              "top     Naomi's friend Noah invited her to his house.   \n",
              "freq                                              125   \n",
              "\n",
              "                                                  buildup  \\\n",
              "count                                                1250   \n",
              "unique                                                 50   \n",
              "top     Mitch thought the book looked cheap and told J...   \n",
              "freq                                                   25   \n",
              "\n",
              "                                                   climax  \\\n",
              "count                                                1250   \n",
              "unique                                                250   \n",
              "top     Kate was very uncomfortable and stood at one c...   \n",
              "freq                                                    5   \n",
              "\n",
              "                                               resolution  \\\n",
              "count                                                1250   \n",
              "unique                                               1250   \n",
              "top     Neil was glad to have joined the conversation,...   \n",
              "freq                                                    1   \n",
              "\n",
              "                                                  outlook  \n",
              "count                                                1250  \n",
              "unique                                               1238  \n",
              "top     Alice and Sam's friendship will continue to gr...  \n",
              "freq                                                    9  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBJ7kZlVV1UP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# combine all columns into one full story\n",
        "df['full'] = df.apply(' '.join, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN8N2ZkgV1UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def add_punctuation_space(text):\n",
        "    #text = re.sub('(?<! )(?=[.,!?()])|(?<=[.,!?()])(?! )', r' \\1 ', text)\n",
        "    text = re.sub(\"([.,!?'()])\", r' \\1 ', text)\n",
        "    # collapse multiple spaces\n",
        "    text = re.sub('\\s{2,}', ' ', text)\n",
        "    return text\n",
        "\n",
        "# input: text with punctuations surrounded with space\n",
        "# output: (size of vocab, list of vocabulary)\n",
        "def get_vocab(text):\n",
        "    vocab = set(text.lower().split())\n",
        "    return (len(vocab), vocab)\n",
        "\n",
        "# input: text with punctuations surrounded with space\n",
        "# output: a dictionary of each unique vocab word and its frequency\n",
        "def get_vocab_counter(text):\n",
        "    return Counter(text.lower().split())\n",
        "\n",
        "# input: filename: vocab.txt filename, vocab: set of vocabulary\n",
        "# output: create vocab file\n",
        "def get_vocab_file(filename, vocab):\n",
        "    with open(filename, 'w') as f:\n",
        "        for token in vocab:\n",
        "            f.write(token + '\\n')\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA13zTuHV1UT",
        "colab_type": "code",
        "outputId": "b11d737b-12ff-47ab-8367-48e9756f43ac",
        "colab": {}
      },
      "source": [
        "df['full'] = df['full'].apply(add_punctuation_space)\n",
        "# collapse the whole column into one string\n",
        "# everything in the dataset in one string\n",
        "story = ' '.join(df['full'])\n",
        "vocab_size, vocab = get_vocab(story)\n",
        "print('The dataset has {} unique words.'.format(vocab_size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dataset has 4569 unique words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrlrnoLpV1UV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_vocab_file('vocab.txt', vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptO-W3pYXCTi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cbf944d0-7d61-4525-ed00-13d4653686f5"
      },
      "source": [
        "# How many vocab in my dataset are not in Bert vocabulary? #\n",
        "my_vocab = [line.strip() for line in open('vocab.txt', 'r').readlines()]\n",
        "unincluded = set(my_vocab) - set(bert_vocab) \n",
        "print(\"There are {} tokens in my dataset that are not in Bert's vocabulary.\".format(len(unincluded)))\n",
        "# write unincluded words to file\n",
        "get_vocab_file('unincluded.txt', unincluded);\n",
        "# inspect unincluded words\n",
        "print(unincluded)\n",
        "# some surround space with punctuations issues - doesn't really matter if I use BertTokenizer"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 792 tokens in my dataset that are not in Bert's vocabulary.\n",
            "{'\"yes\"', 'coupon', 'vowing', '\"be', 'self-conscious', 'foresight', 'strives', '\"surprise\"', 'swoop', 'frustrations', 'pocketing', 'considerate', 'applauded', 'crimed', '\"hey', 'sew', 'childhoods', 'recieved', 'spoiling', 'apologizes', 'detergent', 'kyrie', 'guesture', 'beared', '\"mark', 'impulsive', 'ungrateful', 'contacting', '\"i', 'shyness', 'apathetic', 'funnier', 'chatted', 'partook', 'freinds', 'off-minded', 'cerveza', 'mid-sentence', 'deepen', 'naomi’s', 'hover', 'childishly', 'unappreciative', '\"how', 'repulsive', 'rescheduled', 'profusely', 'candor', '\"misery', 're-establishing', 'stews', 'socialize', 'spooked', 'non-conformity', 'profess', 'retaliated', 'cavs', 'calmer', '\"did', 'ex-boyfriend', 'menstruating', 'charms:', 'heartfelt', '\"evil\"', 'amish', 'gracious', 'reciprocated', 'bossy', 'tremendously', 'bragging', 'uncalled', '‘please', 'occurence', 'restrooms', '\"these', 'clique', 'rekindle', 'budding', 'appreciative', 'problem-solver', 'commonalities', 'event;', 'adaptable', 'haven’t', 'critters', 'byproduct', 'insensitivity', 'browsed', 'validated', 'mistook', 'encouragingly', 'delicacy', 'annoy', 'jane`s', 'ice-creams', 'recreating', 'sorrows', 'rehearsed', 'personalized', 'dictate', 'apologises', 'overwrite', 'revisionist', 'welsher', '\"haunted', 'congratulated', 'calender', 'workable', 'socializing', 'tasty', 'selfie', 'showgirls', 'introverted', 't-shirt', 'shenanigans', 'perish', 'fondest', 'hoot', 'romantically', 'shoplifted', 'jeff`s', 'noah’s', 'injured;', 'uncontrollably', 'anfy', 'collectible', 'kinder', 'midpoint', 'passionately', 'disastrously', 'unbreakable', 'mourned', 'aong', 'recounting', 'abusing', 'obligated', 'brightens', '\"busy', 'unresponsive', 'platonic', 'three-pointer', 'startlingly', 'lukewarm', 'trivia', 'indebted', 'helplessness', 'emailed', 'easygoing', 'irrationally', 'considerd', 'foolishness', 'rudely', 'positiveness', 'nicer', 'pyjamas', 'boasting', 'egift', 'intrude', '20$', 'enganging', 'uninteresting', 'sociable', 'mark’s', 'prick\"', 'politeness', 'about;', 'selfless', 'curdling', 'fine;', 'thoughtfulness', 'scolding', 'ecstatic', '8pm', 'situtation', 'distancing', 'broached', 'profanity', 'consoled', 'onone', 'impractical', 'jokingly', '\"accident\"', 'pessimist', 'him:', 'camaraderie', 'like-minded', 'refill', 'nomi', 'cowardly', 'solidifying', 'vocally', 'unplugged', '\"yeah', 'dejected', 'wuss', 'matthew’s', 'agonizing', 'criticize', 'home-', 'leashes', 'tip-toed', '2600', 'selfishly', 'reminiscing', 'channeled', 'fondness', 'old-school', 'anyones', '\"guy', 'impaled', 'ex-girlfriend', 'snitch', 'believable', 'unkind', 'self-discovery', 'associating', 'professing', 'skimpy', 'hor', 'flattered', 'biked', 'let-down', 'awkwardness', 'tiredness', 'smoker', 'refrained', 'proffered', 'ribbing', 'inappropriately', 'joyful', 'wins/losses', 'photoshoot', 'don’t', 'back--this', 'handmade', 'flustered', 'relatable', 'emma`s', 'togheter', 'someone’s', 'housewarming', 'abashed', 'hershey', 'tact', 'side-business', 'spectres', 'embarrass', 'panicking', '\"baby', 'crochet', '\"absolutely', 'overstimulated', 'things\"', '\"the', 'voucher', '\"good\"', 'roommates', 'prioritization', 'symbolized', 'sheepishly', 'roulette', 'appaled', 'wont', 'pranked', 'marl', 'oiled', 'hospitable', 'gadget', 'arguement', 'scrumptious', 'joyfully', 'sporty', 'friend’s', 'bleach', 'nervousness', 'heirloom', 'judgmental', 'whack', 'mins', 'gluing', 'back-and-forth', 'restaurant’s', 'naughtiness', 'obtuse', '“why', 'idiotic', 'disrespectful', 'he`ll', 'napkins', 'snickering', 'birthdate', 'lightness', 'roomates', 'laces', '--', 'jacob’s', 'accomplishing', 'forgave', 'chitchatted', 'cellphone', '“i', 'plums', 'tweeted', 'otherand', 'comforted', 'verifying', 'fakes', 'professed', 'ditched', 'bettering', 'wisely', 'insufferable', 'work\"', 'chancing', 'apologizing', 'screech', 'rapport', 'strenghthen', '‘is', 'valuing', 'quarrels', 'errand', 'devolve', 'transpired', 'shopkeeper', 'blames', '\"wow', 'punches;', 'while:', 'silences', 'annoyed;', 'togeather', 'candid', 'livid', 'showering', 'girly', 'joysticks', 'altercation', 'leash\"', 'candleholder', '$20', 'offend', 'meanwhile;', 'yall', 'heartbroken', 'oddities', '$60', 'infuriated', 'cooperated', 'jeff’s', 'appreciates', 'friendliness', 'respectfulness', 'twig', 'sunbathing', 'scenerio', 'stomachache', 'fashionista', 'teamwork', '\"oh', 'recluse', 'reexperience', 'thing\"', 'tweets', 'overreacted', 'calmness', 'vandalism', 'tummies', 'yogurt', 'braved', '\"really', 'plum\"', '\"dear', '2am', 'pave', 'exhilarated', 'roadblocks', 'saucers', 'reestablished', 'eye-to-eye', 'obliges', 'well-intentioned', 'bursted', 'toenail', 'etiquette', 'talkative', 'hereafter', 'jame', 'whosever', 'friendship;', 'marathons', 'fooling', 'appreciating', 'refreshed', 'bucolic', 'persistency', 'slighted', 'effortless', 'jeopardize', 'berated', 'matthew:', 'pho', 'browsing', 'boy-crazy', 'susans', 'grandfathers', 'rudeness', '\"jeff', '\"it', 'noami', 'pranks', 'scold', 'birthdays', 'trustworthy', 'tweet', 'transformer', 'so-called', 'self-esteem', 'hurtfully', 'deletes', 'naomi`s', 'dampened', 'snapchat', 'amends', 'chipped', 'nicest', 'drawn-out', 'mercilessly', 'guests;', 'cementing', 'toether', 'hectic', 'stomach--maybe', 'pushover', 'shelia', 'frugality', 'bestiee', 'joyous', 'bummer', '\"no', 'inconvenience', 'treasured', 'games\"', 'doubel', 'plauded', 'steph', 'there’ll', 'kate’s', 'mend', 'girlfriend\"', 'pasts', 'cherished', 'superstars', 'voicing', 'lemonade', 'fanciest', 'auditioning', 'fightened', 'reticent', 'pinpoint', 'funniest', 'inconsiderate', 'immaturity', 'offending', 'overpaid', 'verbally', 'hav', 'understandable', '`s', 'otherhand', 'attentive', 'confided', 'inseparable', 'figurine', 'excitment', '“if', 'waste:', 'offhandedly', 'pre-school', 'laughed/cried', 'favor/gesture', 'foamy', 'befriend', 'disappoint', 'mistaking', 'james’', 'gift;', 'leaver', 'nourish', 'dependable', 'they`ve', 'clueless', 'quadruple', 'dine', 'penchant', 'unforgettable', 'carped', 'meme', 'deteriorate', 'fullest', 'shyly', 'bungee', 'buzzer', 'unplug', '\"what', 'sushi', 'rambunctious', 'dismal', 'reaffirmed', 'abig', 'to;', 'wwi', 'carve', 'misfortune', 'swags', 'introvert', 'shreds', 'blot', 'cemetery:', 'undependable', 'dined', 'snobby', 'lettuce', 'passer-by', 'namoi', 'cherish', 'distanced', 'receptive', '$50', 'sabotaged', 'shying', 're-occurring', 'ailing', 'resorted', 'impulsiveness', '\"don', 'passer-bys', 'thank-you', 'insensitive', 'unbothered', 'payed', 'pedicure', 'murky', 'eachother', 'reclusive', 'redundancy', 'is’', 'manic', 'one-on-one', '$40', 'ambiance', 'chitchatting', 'amy’s', 'flakey', 'reciprocate', 'happend', 'buckets', 'pedaled', 'holier', '\"everyone', 'beacuse', 'couldn’t', 'quipped', 'subtweeted', 'cheerleaders', 'seperate', 'forgiving', 'come;', 'john’s', 'lessen', 'spoons', 'unplanned', 'embarassement', 'slut', 'hangout', 'pong', 'reconnect', 'outage', 'empathetic', 'high-fives', 'keyed', 'tranquility', 'delve', 'indulge', 'concoled', 'companionship', 'trespassing', 'brighten', 'janes', 'rashly', 'say;', 'miscalculations', 'expained', 'corny', 'didnt', 'outages', 'you\"', 'hurtful', 'likeminded', 'e-card', 'sulked', 'insecure', '\"knife\"', '\"who', 'coasters', 'angrier', 'mispronounced', 'can’t', 'bummed', 'hangouts', 'inot', 'nerve-wrecking', 'blossomed', 'shackles', 'receded', 'pleasently', 'chided', 'evaporated', 'friendzone', 'profanities', 'tragedies', 'resents', 'complements', 'texting', 'snubbed', 'skid', 'nonsensical', 'partying', 'googled', 'chang’s', 'crushes', 'dumbstruck', 'videogames', 'jane’s', 'nothingness', 'plagiarize', 'jacob`s', 'jenny’s', 'mindset', 'tandrum', 'hindered', 'skirting', 'congratulate', 'meetup', 'recommited', 'discreetly', 'devolved', 'cramps', 'endlessly', 'embarassed', 'giant-eyed', 'haha', 'pressurize', 'inner-state', 'shamed', 'ubers', 'wrongdoing', 'first-aid', 'what’s', 'aomething', 'again;', 'then”', 'families’', 'hateful', 'rebuffed', '\"this', 'hustle', 'olivia’s', '$100', 'irresponsible', 'accommodating', 'seconded', 'pied', 'oblige', 'mediate', 'reenactments', 'lackadaisical', 'surprise\"', 'dwindled', 'unintentionally', 'eases', 'tony’s', 'desserts', 'pre-planned', 'equidistant', 'begrudgingly', 'exponentially', 'bragged', 'overwhelm', 'harassing', 'resentful', 'candlelight', 'gameboy', 'broaden', 'selfishness', 'disregarding', 'gifting', 'mattew', 'displeased', 'stressful', 'spooky', 'traditionalist', 'happenings', 'accompanies', 'thier', 'emma’s', 'didn’t', 'hiccup', 'wholesome', 'aversion', 'hardships', 'wallowed', 'deceitful', 'now\"', 'wasnt', 'unselfish', 'messaged', 'unresolved', 'durant', 'naiomi', 'pies', 'tham', 'mitch’s', 'elated', 'phoned', 'coy', 'handlebars', 'sing-songed', 'coolly', 'sam’s', 'mortified', 'tolerating', 'plugged', 'rinses', 'incompetent', 'me\"', 'chastised', 'suprise', 'calm:', 'sleepover', 'cant', 'lightheartedly', 'troubling', 'meet-up', 'other’s', 'subtlety', 'life’s', 'hand-made', 'giang', '‘i’d', 'diligent', 'yawning', 'alot', 'apologise', 'whim', 'crybaby', 'graciously', 'admirable', 'unrequited', 'deflection', 'competitively', 'other;', 'distaste', 'impolite', 'greatful', 'reprimanded', 'hiker', 'cricket-loving', '\"nope', 'flops', 'soothed', 'faked', 'unflattering', 'memento', 'meanest', 'pronounce', 'carelessly', 'shunned', 're-gifting', 'mathew`s', 'pent', 'shopped', 'birythday', 'trudged', 'alice’s', 'untrustworthy', 'apologised', '\"you', 'guests’', 'kart', 'emailing', 'saddened'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l_TsprqV1UX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use BertTokenizer\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5YtYM0_bMRd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146,
          "referenced_widgets": [
            "6a10dcb61b6a419bb08fb365d695cf82",
            "e64363040e7f4e498cf4b264d0ab4ae8",
            "9b871876a776460a9fbae2724329d68e",
            "3f62010d71fd445c9a4a20ef08f47b3a",
            "06485a925a44468aa74ff019c4ed6099",
            "1c1958cd3dff49f18e4fc21e6cd8afa4",
            "e3b334b697504143be519326bd214bd3",
            "7a041651df1a490ebe3a48eac5aadbf2"
          ]
        },
        "outputId": "9fc76868-3d47-4ee5-c6f2-9ca528fbb004"
      },
      "source": [
        "# load tokenizer\n",
        "# Load the BERT tokenizer.\n",
        "from transformers import BertTokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a10dcb61b6a419bb08fb365d695cf82",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1jXxVcubT7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "67f220d9-fd8f-4400-9503-eea90409a89a"
      },
      "source": [
        "# see sample tokenized sentence\n",
        "sentence = 'They remembered a lot of things that they did together back then — amusement park, haunted house adventure and many others.'\n",
        "# Print the original sentence.\n",
        "print(' Original: ', sentence)\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentence))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentence)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  They remembered a lot of things that they did together back then — amusement park, haunted house adventure and many others.\n",
            "Tokenized:  ['they', 'remembered', 'a', 'lot', 'of', 'things', 'that', 'they', 'did', 'together', 'back', 'then', '—', 'amusement', 'park', ',', 'haunted', 'house', 'adventure', 'and', 'many', 'others', '.']\n",
            "Token IDs:  [2027, 4622, 1037, 2843, 1997, 2477, 2008, 2027, 2106, 2362, 2067, 2059, 1517, 9778, 2380, 1010, 11171, 2160, 6172, 1998, 2116, 2500, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW82xn6ycK2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Need to add special tokens like [CLS], etc ###"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}